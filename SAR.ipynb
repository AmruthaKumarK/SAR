{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmruthaKumarK/SAR/blob/main/SAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H71EtiHRTABZ"
      },
      "outputs": [],
      "source": [
        "# # **1. Importing Libraries and Setting Environment Variables**\n",
        "\n",
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import numpy as np\n",
        "from skimage import io, img_as_float, img_as_ubyte\n",
        "from skimage.restoration import (\n",
        "    denoise_nl_means,\n",
        "    denoise_tv_chambolle,\n",
        "    denoise_wavelet,\n",
        "    denoise_bilateral\n",
        ")\n",
        "from skimage.restoration import estimate_sigma\n",
        "from skimage.util import random_noise\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # **2. Image Loading and Preprocessing**\n",
        "\n",
        "def load_images(image_paths, size=(128, 128)):\n",
        "    images = []\n",
        "    for path in image_paths:\n",
        "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if image is None:\n",
        "            print(f\"Error: Unable to load image at {path}\")\n",
        "            continue  # Skip this image and move to the next one\n",
        "        image = cv2.resize(image, size)\n",
        "        image = image / 255.0  # Normalize to [0, 1]\n",
        "        images.append(image)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load and preprocess a single image for denoising example\n",
        "image_path = 'full dataset/archive/v_2/agri/s1/ROIs1868_summer_s1_59_p11.png'  # Update with your local path\n",
        "original_image = img_as_float(io.imread(image_path, as_gray=True))\n",
        "noisy_image = random_noise(original_image, mode='speckle', var=0.01)\n"
      ],
      "metadata": {
        "id": "SAt6D6LbmqKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # **3. Applying Traditional Denoising Methods**\n",
        "\n",
        "# Estimate sigma for NLM\n",
        "sigma_est = np.mean(estimate_sigma(noisy_image))\n",
        "\n",
        "# Apply NLM and its combinations\n",
        "denoised_image_nlm = denoise_nl_means(noisy_image, h=1.0 * sigma_est, fast_mode=True, patch_size=7, patch_distance=11, channel_axis=None)\n",
        "\n",
        "# Combinations with NLM\n",
        "denoised_image_nlm_tv = denoise_tv_chambolle(denoise_nl_means(noisy_image, h=1.0 * sigma_est, fast_mode=True, patch_size=7, patch_distance=11, channel_axis=None), weight=0.1)\n",
        "denoised_image_nlm_wavelet = denoise_wavelet(denoise_nl_means(noisy_image, h=1.0 * sigma_est, fast_mode=True, patch_size=7, patch_distance=11, channel_axis=None), method='BayesShrink', mode='soft')\n",
        "denoised_image_nlm_bilateral = denoise_bilateral(denoise_nl_means(noisy_image, h=1.0 * sigma_est, fast_mode=True, patch_size=7, patch_distance=11, channel_axis=None), sigma_color=0.05, sigma_spatial=15)\n",
        "\n",
        "# Combinations of the above\n",
        "denoised_image_nlm_tv_wavelet = denoise_wavelet(denoise_tv_chambolle(denoise_nl_means(noisy_image, h=1.0 * sigma_est, fast_mode=True, patch_size=7, patch_distance=11, channel_axis=None), weight=0.1), method='BayesShrink', mode='soft')\n",
        "denoised_image_nlm_tv_bilateral = denoise_bilateral(denoise_tv_chambolle(denoise_nl_means(noisy_image, h=1.0 * sigma_est, fast_mode=True, patch_size=7, patch_distance=11, channel_axis=None), weight=0.1), sigma_color=0.05, sigma_spatial=15)\n",
        "\n",
        "# Final combination of all methods\n",
        "denoised_image_nlm_tv_wavelet_bilateral = denoise_bilateral(\n",
        "    denoise_wavelet(\n",
        "        denoise_tv_chambolle(\n",
        "            denoise_nl_means(noisy_image, h=1.0 * sigma_est, fast_mode=True, patch_size=7, patch_distance=11, channel_axis=None),\n",
        "            weight=0.1\n",
        "        ),\n",
        "        method='BayesShrink',\n",
        "        mode='soft'\n",
        "    ),\n",
        "    sigma_color=0.05,\n",
        "    sigma_spatial=15\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ri-xs2SnnH_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # **4. Defining the CNN Model for Despeckling**\n",
        "\n",
        "def build_despeckle_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # First convolutional layer with more filters\n",
        "    x = Conv2D(128, (3, 3), padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks with more filters\n",
        "    for _ in range(8):\n",
        "        residual = Conv2D(128, (3, 3), padding='same')(x)\n",
        "        residual = BatchNormalization()(residual)\n",
        "        residual = Activation('relu')(residual)\n",
        "        residual = Conv2D(128, (3, 3), padding='same')(residual)\n",
        "        residual = BatchNormalization()(residual)\n",
        "        x = Add()([x, residual])\n",
        "\n",
        "    # Last convolutional layer\n",
        "    outputs = Conv2D(1, (3, 3), padding='same')(x)\n",
        "    outputs = BatchNormalization()(outputs)\n",
        "    outputs = Activation('sigmoid')(outputs)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "mwm6gQmDnMzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # **5. Training the CNN Model**\n",
        "\n",
        "def main():\n",
        "    # Example image paths\n",
        "    speckled_image_paths = [\n",
        "        \"full dataset/archive/v_2/agri/s1/ROIs1868_summer_s1_59_p2.png\",\n",
        "        \"full dataset/archive/v_2/agri/s1/ROIs1868_summer_s1_59_p3.png\"\n",
        "    ]\n",
        "    clean_image_paths = [\n",
        "        \"greyscale/ROIs1868_summer_s2_59_p2_greyscale.png\",\n",
        "        \"greyscale/ROIs1868_summer_s2_59_p3_greyscale.png\"\n",
        "    ]\n",
        "\n",
        "    # Load and preprocess images\n",
        "    X = load_images(speckled_image_paths).reshape(-1, 128, 128, 1)\n",
        "    Y = load_images(clean_image_paths).reshape(-1, 128, 128, 1)\n",
        "\n",
        "    # Ensure that the number of images loaded is the same\n",
        "    if len(X) != len(Y):\n",
        "        print(\"Error: Number of speckled and clean images do not match!\")\n",
        "        return\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build and compile the model\n",
        "    input_shape = (128, 128, 1)\n",
        "    model = build_despeckle_model(input_shape)\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    batch_size = 32\n",
        "    epochs = 5\n",
        "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, Y_val))\n"
      ],
      "metadata": {
        "id": "HSJhM2WZnPl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # **6. Predicting and Saving the Despeckled Image**\n",
        "\n",
        "    # Predict on a new SAR image\n",
        "    test_image_path = 'full dataset/archive/v_2/agri/s1/ROIs1868_summer_s1_59_p2.png'  # Replace with your test image path\n",
        "    test_image = load_images([test_image_path]).reshape(1, 128, 128, 1)\n",
        "    despeckled_image = model.predict(test_image)\n",
        "\n",
        "    # Save the despeckled image\n",
        "    despeckled_image = despeckled_image.reshape(128, 128)\n",
        "    despeckled_image = (despeckled_image * 255).astype('uint8')\n",
        "    io.imsave('despeckled_image_cnn.png', despeckled_image)\n",
        "\n",
        "    # Save the traditional denoising output\n",
        "    denoised_image_nlm_tv_wavelet_bilateral_uint8 = img_as_ubyte(denoised_image_nlm_tv_wavelet_bilateral)\n",
        "    io.imsave('despeckled_image7.png', denoised_image_nlm_tv_wavelet_bilateral_uint8)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "DPBle72CnTsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}